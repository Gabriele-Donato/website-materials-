{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdffe759-a846-4f42-be0c-64205b108e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp \n",
    "import asyncio\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import dateutil, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cb8938-3db4-4839-887a-268d2e1d93b1",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This is the first component of the project advertised on my website.\n",
    "\n",
    "The RESOURCE_EXTRACTOR takes a list of resources manually clustered (this ensures quality), and extracts the html out of them.\n",
    "\n",
    "The update to the extractor will include a better handling of the resource grouping under the url_assigner (so that it wont be necessary to initialise manually, for each resource cluster, 'self.output').\n",
    "\n",
    "Note that the below design is functional to a program able, in perspective, to deal with sources from a number of different websites.\n",
    "\n",
    "The weekly updates will include:\n",
    "- A precise terminology, commented and improved functions (accepted data type specification, output type specification etc...).\n",
    "- A parser able to extract dates and structure the text.\n",
    "\n",
    "**soon:**\n",
    "\n",
    "- A processing pipeline  (pyspark).\n",
    "- A data storing mechanism (pydoop)\n",
    "(I do not have a server so I will start the spark and hadoop servers locally)\n",
    "\n",
    "When all the above will be completed I will try to model the data and see whether it is possible to extract some insights about the evolution of this war (a small anticipation of what I am thinking: _*Mathematics and Politics: Strategy, Voting, Power, and Proof*_ by Alan D. Taylor and Allison M. Pacelli: [here](https://link.springer.com/book/10.1007/978-0-387-77645-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2284634c-9a06-4494-bb4f-72987b226c25",
   "metadata": {},
   "source": [
    "# Section I - Retrieving HTML \n",
    "\n",
    "The purpose of the ResourceExtractor is navigating on the ISW website pages and retrieve from them the html. The result is stored in the variable 'output'. Note how the code is defined in a general way: self.all_resources is a dictionary allowing for the integration of multiple resources. This does not mean that the code can be extended to a number of arbitrary resources. For the latter funcionality to be available, it would be necessary to devise a generalise TextParser (defined in Section II). Since the present project is an experiment with certain data engineering tools more that a scraper, the task of such generalisation **will be tackled upon completition**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af3a6e0-df14-41d8-a02b-e1777aa85174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.russo_ukranian_war_sources = [\n",
    "            'https://www.understandingwar.org/backgrounder/ukraine-conflict-updates',\n",
    "            'https://www.understandingwar.org/backgrounder/ukraine-conflicts-updates-january-2-may-31-2024',\n",
    "            ]\n",
    "        self.all_resources = {'ISW_Russia_Ukraine_War': self.russo_ukranian_war_sources}\n",
    "        self.output = {key:'' for key in self.all_resources}\n",
    "    \n",
    "    def url_assigner(self, url):\n",
    "        for key, value_list in self.all_resources.items():\n",
    "            if url in value_list:\n",
    "                return str(key)\n",
    "        return f'{url} : NOT IDENTIFIED'\n",
    "        \n",
    "    async def text_extractor(self, session, url):\n",
    "        key = self.url_assigner(url)\n",
    "        async with session.get(url) as response:\n",
    "            await asyncio.sleep(1.5)  \n",
    "            if response.status == 200:\n",
    "                self.output[key] += await response.text()\n",
    "\n",
    "    async def run_text_extractor(self):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [self.text_extractor(session, resource_page) for resource_list in self.all_resources.values() for resource_page in resource_list]\n",
    "            await asyncio.gather(*tasks)\n",
    "            return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecc763b1-ce89-4424-822c-790a8819c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ResourceExtractor()\n",
    "output  = await extractor.run_text_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac0b93-c05a-4106-9c67-d4a38dae6857",
   "metadata": {},
   "source": [
    "# Section II - Retrieving Textual Elements\n",
    "\n",
    "In this section I define a class called TextParser, note that the class is tailored to the websites being considered and cannot be applied on any website.\n",
    "\n",
    "There are two main options for generalising the methods of this class, and they are dependent on what is meant with \"generalisation\".\n",
    "#### generalisation = integration of multiple resources\n",
    "In this case it suffices considering a finite set of websites and design methods that exploits the commonalities between them, or that change depending on the website. In this case the scraper would be generalise to n-resources (whereas currently it can be applied to only one).\n",
    "\n",
    "#### generalisation = widespread applicability\n",
    "In this case we would like a set of methods that apply to any website. To do this it is necessary to devise an intelligent (or adaptive) program. Personally, I see the opportunity for Bayesian classifiers, but we'll see as soon as the \"important\" parts of the project will be completed: we're here to use Pyspark and Hadoop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b3d0294-dd7f-4f44-9cd6-5f27b3e54f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"In this version I have systematised the code uploaded this morning (2024-07-23) and prepared\n",
    "it for an integration with pydoop, that will be accomplished tomorrow (2024-07-24).\n",
    "The present code is updated at h. 21.58\"\"\"\n",
    "\n",
    "class TextParser:\n",
    "    def __init__(self, resource_dictionary):\n",
    "        self.resource_dictionary = resource_dictionary\n",
    "        self.date_paragraph_map = {}\n",
    "\n",
    "    def page_dissecter(self):\n",
    "        soups = []\n",
    "        for html_text in self.resource_dictionary.values():\n",
    "            soup = BeautifulSoup(html_text, 'html.parser')\n",
    "            soups.append(soup)\n",
    "        return [[p_tag.text for p_tag in soup.find_all('p')]for soup in soups]\n",
    "\n",
    "    def is_date(self, text):\n",
    "        try:\n",
    "            possible_date = dateutil.parser.parse(text)\n",
    "            return True, possible_date\n",
    "        except:\n",
    "            return False, None\n",
    "\n",
    "    def shuffler(self):\n",
    "        resource_p_tags = self.page_dissecter()\n",
    "        current_date = None\n",
    "        for resource in resource_p_tags:\n",
    "            for paragraph in resource:\n",
    "                is_date, parsed_date = self.is_date(paragraph)\n",
    "                if is_date:\n",
    "                    current_date = parsed_date\n",
    "                elif current_date:\n",
    "                    if current_date not in self.date_paragraph_map:\n",
    "                        self.date_paragraph_map[current_date] = \"\"\n",
    "                    self.date_paragraph_map[current_date] += paragraph\n",
    "        return self.date_paragraph_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a239e339-7b4c-4faf-90b0-1d21cdd62f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextParser(output)\n",
    "s = tp.shuffler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fe72bdf-3f3c-4276-9747-f8ec93c7b0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.datetime(2024, 7, 22, 19, 30): 'Note: The data cut-off for this product was 1:30pm ET on July 22. ISW will cover subsequent reports in the July 23 Russian Offensive Campaign Assessment.Russia and North Korea are pursuing increased cooperation in the judicial sphere.\\xa0Russian Prosecutor General Igor Krasnov arrived in Pyongyang, North Korea and met with his North Korean counterpart Kim Chol Won on July 22, marking the first time that a Russian Prosecutor General has visited North Korea.[1]\\xa0Krasnov and Kim reportedly discussed avenues for continued cooperation and signed an agreement for joint work between the Russian and North Korean prosecutor generals\\' offices for 2024–2026.[2]\\xa0The Russian and North Korean prosecutor general\\'s offices have notably maintained dialogue since 2010 through a separate cooperation agreement, but the new agreement will likely be much more focused in scope, reflecting intensified Russo–North Korean cooperation over the past year.[3]\\xa0Krasnov emphasized the importance of \"establishing a regula....CONTINUES',\n",
       " datetime.datetime(2024, 7, 20, 17, 50): \"Ukrainian President Volodymyr Zelensky spoke with former US President and Republican presidential nominee Donald Trump on July 19 and discussed an end-state to the war in Ukraine.\\xa0Zelensky stated that\\xa0he agreed to talk with Trump about steps that will produce a fair and truly lasting peace at a future personal meeting.[1]\\xa0Trump stated that both Russia and Ukraine will be able to come together and negotiate a deal that ends the war.[2]\\xa0The Kremlin continues to indicate that it is only interested in a negotiated settlement that results in Ukrainian capitulation and paves the way for Russia to destroy Ukrainian statehood, however.[3]\\xa0Zelensky has recently stressed that Ukraine must significantly weaken Russia's battlefield position in order to develop a stronger negotiating position for future peace negotiations, and Ukrainian leadership continues to call for the restoration of Ukraine's territorial integrity and long-term security guarantees for Ukraine as part of any lasting peace.[4]\\xa0W....CONTINUES\",\n",
       " datetime.datetime(2024, 7, 19, 18, 35): 'Ukrainian President Volodymyr Zelensky reiterated the importance of developing an international consensus for pursuing peace negotiations to end the war in Ukraine.\\xa0Zelensky stated during an interview with the BBC published on July 18 that the world needs to develop a united consensus on a possible end state for the war in Ukraine and present this consensus to Russia in order to encourage Russia to come to the negotiating table.[1]\\xa0Zelensky added that diplomacy will be an important element of restoring Ukraine\\'s territorial integrity and that Ukraine does not necessarily need to liberate all of its territory \"by force\" but must significantly weaken Russia\\'s battlefield position in order to develop a stronger negotiating position for future peace negotiations. Zelensky and other Ukrainian officials have consistently presented their vision for a negotiated settlement for the war in Ukraine, which includes the restoration of Ukraine\\'s territorial integrity and long-term security guarantee....CONTINUES'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I slice the output to show the final results since GitHub cannot render them \n",
    "sliced_dict = {}\n",
    "count = 0\n",
    "K = 1000\n",
    "for key, value in tp.date_paragraph_map.items():\n",
    "    count += 1\n",
    "    sliced_dict[key] = value[:K] + '....CONTINUES'\n",
    "    if count >= 3:\n",
    "        break\n",
    "sliced_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bca63-796f-40c0-b700-4076d3954765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
