{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b2ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp \n",
    "import asyncio\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import dateutil, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f054f0",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This is the first component of the project advertised on my website.\n",
    "\n",
    "The RESOURCE_EXTRACTOR takes a list of resources manually clustered (this ensures quality), and extracts the html out of them.\n",
    "\n",
    "The update to the extractor will include a better handling of the resource grouping under the url_assigner (so that it wont be necessary to initialise manually, for each resource cluster, 'self.output').\n",
    "\n",
    "Note that the below design is functional to a program able, in perspective, to deal with sources from a number of different websites.\n",
    "\n",
    "The weekly updates will include:\n",
    "- A precise terminology, commented and improved functions (accepted data type specification, output type specification etc...).\n",
    "- A parser able to extract dates and structure the text.\n",
    "\n",
    "**soon:**\n",
    "\n",
    "- A processing pipeline  (pyspark).\n",
    "- A data storing mechanism (pydoop)\n",
    "(I do not have a server so I will start the spark and hadoop servers locally)\n",
    "\n",
    "When all the above will be completed I will try to model the data and see whether it is possible to extract some insights about the evolution of this war (a small anticipation of what I am thinking: _*Mathematics and Politics: Strategy, Voting, Power, and Proof*_ by Alan D. Taylor and Allison M. Pacelli: [here](https://link.springer.com/book/10.1007/978-0-387-77645-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f772176",
   "metadata": {},
   "source": [
    "# Section I - Retrieving HTML \n",
    "\n",
    "The purpose of the ResourceExtractor is navigating on the ISW website pages and retrieve from them the html. The result is stored in the variable 'output'. Note how the code is defined in a general way: self.all_resources is a dictionary allowing for the integration of multiple resources. This does not mean that the code can be extended to a number of arbitrary resources. For the latter funcionality to be available, it would be necessary to devise a generalise TextParser (defined in Section II). Since the present project is an experiment with certain data engineering tools more that a scraper, the task of such generalisation **will be tackled upon completition**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ed666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.russo_ukranian_war_sources = [\n",
    "            'https://www.understandingwar.org/backgrounder/ukraine-conflict-updates',\n",
    "            'https://www.understandingwar.org/backgrounder/ukraine-conflicts-updates-january-2-may-31-2024',\n",
    "            ]\n",
    "        self.all_resources = {'ISW_Russia_Ukraine_War': self.russo_ukranian_war_sources}\n",
    "        self.output = {key:'' for key in self.all_resources}\n",
    "    \n",
    "    def url_assigner(self, url):\n",
    "        for key, value_list in self.all_resources.items():\n",
    "            if url in value_list:\n",
    "                return str(key)\n",
    "        return f'{url} : NOT IDENTIFIED'\n",
    "        \n",
    "    async def text_extractor(self, session, url):\n",
    "        key = self.url_assigner(url)\n",
    "        async with session.get(url) as response:\n",
    "            await asyncio.sleep(1.5)  \n",
    "            if response.status == 200:\n",
    "                self.output[key] += await response.text()\n",
    "\n",
    "    async def run_text_extractor(self):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [self.text_extractor(session, resource_page) for resource_list in self.all_resources.values() for resource_page in resource_list]\n",
    "            await asyncio.gather(*tasks)\n",
    "            return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5756a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ResourceExtractor()\n",
    "output  = await extractor.run_text_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f9336",
   "metadata": {},
   "source": [
    "# Section II - Retrieving Textual Elements\n",
    "\n",
    "In this section I define a class called TextParser, note that the class is tailored to the websites being considered and cannot be applied on any website.\n",
    "\n",
    "There are two main options for generalising the methods of this class, and they are dependent on what is meant with \"generalisation\".\n",
    "#### generalisation = integration of multiple resources\n",
    "In this case it suffices considering a finite set of websites and design methods that exploits the commonalities between them, or that change depending on the website. In this case the scraper would be generalise to n-resources (whereas currently it can be applied to only one).\n",
    "\n",
    "#### generalisation = widespread applicability\n",
    "In this case we would like a set of methods that apply to any website. To do this it is necessary to devise an intelligent (or adaptive) program. Personally, I see the opportunity for Bayesian classifiers, but we'll see as soon as the \"important\" parts of the project will be completed: we're here to use Pyspark and Hadoop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44327d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"In this version I have systematised the code uploaded this morning (2024-07-23) and prepared\n",
    "it for an integration with pydoop, that will be accomplished tomorrow (2024-07-24).\n",
    "The present code is updated at h. 21.58\"\"\"\n",
    "\n",
    "class TextParser:\n",
    "    def __init__(self, resource_dictionary):\n",
    "        self.resource_dictionary = resource_dictionary\n",
    "        self.date_paragraph_map = {}\n",
    "\n",
    "    def page_dissecter(self):\n",
    "        soups = []\n",
    "        for html_text in self.resource_dictionary.values():\n",
    "            soup = BeautifulSoup(html_text, 'html.parser')\n",
    "            soups.append(soup)\n",
    "        return [[p_tag.text for p_tag in soup.find_all('p')]for soup in soups]\n",
    "\n",
    "    def is_date(self, text):\n",
    "        try:\n",
    "            possible_date = dateutil.parser.parse(text)\n",
    "            return True, possible_date\n",
    "        except:\n",
    "            return False, None\n",
    "\n",
    "    def shuffler(self):\n",
    "        resource_p_tags = self.page_dissecter()\n",
    "        current_date = None\n",
    "        for resource in resource_p_tags:\n",
    "            for paragraph in resource:\n",
    "                is_date, parsed_date = self.is_date(paragraph)\n",
    "                if is_date:\n",
    "                    current_date = parsed_date\n",
    "                elif current_date:\n",
    "                    if current_date not in self.date_paragraph_map:\n",
    "                        self.date_paragraph_map[current_date] = \"\"\n",
    "                    self.date_paragraph_map[current_date] += paragraph\n",
    "        return self.date_paragraph_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cddb4138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname ET identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "tp = TextParser(output)\n",
    "s = tp.shuffler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe44eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.datetime(2024, 5, 31, 18, 45): 'US and German officials confirmed that the United States and Germany have changed their policies to allow Ukraine to use US- and German-provided weapons to strike Russian territory with some restrictions but did not offer precise details about these restrictions.\\xa0Secretary of State Antony Blinken stated on May 31 that President Joe Biden approved Ukraine\\'s use of US-supplied weapons to defend against Russian aggression, \"including against Russian forces that are massing on the Russian side of the border and then attacking into Ukraine.\"[1]\\xa0Western media reported on May 30 that the Biden administration gave Ukraine permission to use US-provided weapons, including GMLRS rockets, for \"counter-fire purposes\" against the Russian forces conducting assaults in northern Kharkiv Oblast but has not changed its policy restricting Ukraine from using US-provided weapons, such as ATACMS, to conduct long-range strikes elsewhere into Russia.[2]\\xa0Blinken\\'s May 31 statement did not specify which US-provi....CONTINUES',\n",
       " datetime.datetime(2024, 5, 30, 20, 50): 'Click\\xa0here\\xa0to see ISW’s interactive map of the Russian invasion of Ukraine. This map is updated daily alongside the static maps present in this report.Click\\xa0here\\xa0to see ISW’s 3D control of terrain topographic map of Ukraine. Use of a computer (not a mobile device) is strongly recommended for using this data-heavy tool.Click\\xa0here\\xa0to access ISW’s archive of interactive time-lapse maps of the Russian invasion of Ukraine. These maps complement the static control-of-terrain map that ISW produces daily by showing a dynamic frontline. ISW will update this time-lapse map archive monthly.Note: The data cut-off for this product was 1:30pm ET on May 30. ISW will cover subsequent reports in the May 31 Russian Offensive Campaign Assessment.US President Joe Biden reportedly approved a policy change that will permit Ukraine to use US-provided weapons, including GMLRS rockets — but not longer-range ATACMS missiles — to strike within Russian territory near the border with Kharkiv Oblast.\\xa0US officials a....CONTINUES',\n",
       " datetime.datetime(2024, 5, 29, 19, 15): 'Advisor to the Head of the Ukrainian President\\'s Office Mykhaylo Podolyak stated that US-provided military aid has started arriving on the frontline but that it will take \"weeks\" for the gradual increase in US-provided military aid to reach \"critical volumes.\"[1]\\xa0Podolyak told\\xa0Bloomberg\\xa0in an article published on May 29 that Russian forces currently have the \"absolute advantage\" in shells and missiles and that Russian forces will continue to try to advance along the frontline presumably to take advantage of the time before US military assistance arrives in sufficient quantities at the front. Podolyak warned that Russia may be trying to force Ukraine and its allies to freeze the current frontline — a situation that ISW has long assessed would be advantageous to Russia by giving the Russian military time to reconstitute and prepare for renewed aggression against Ukraine.[2]\\xa0Additional Western military assistance will also likely take time to reach the frontlines and to be properly integr....CONTINUES'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I slice the output to show the final results since GitHub cannot render them \n",
    "sliced_dict = {}\n",
    "count = 0\n",
    "K = 1000\n",
    "for key, value in tp.date_paragraph_map.items():\n",
    "    count += 1\n",
    "    sliced_dict[key] = value[:K] + '....CONTINUES'\n",
    "    if count >= 3:\n",
    "        break\n",
    "sliced_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66febb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b32786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41355cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
